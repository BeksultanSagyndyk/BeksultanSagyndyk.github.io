---
layout: post
title: "Paper review: Mistral 7B"
subtitle: "Unleashing Mistral 7B: The Game-Changing 7-Billion-Parameter Beast?"
gh-repo: BeksultanSagyndyk/BeksultanSagyndyk.github.io
gh-badge: [star, follow]
tags: [LLM, long input transformers]
comments: true
author: Beksultan Sagyndyk
---
![image](https://github.com/BeksultanSagyndyk/BeksultanSagyndyk.github.io/assets/46630209/24c6dbd0-69f2-4698-8f84-7ff91d3c5a32)

Mistral 7B outperforms the best open 13B
model (Llama 2) across all evaluated benchmarks, and the best released 34B
model (Llama 1) in reasoning, mathematics, and code generation. 
Code: https://github.com/mistralai/mistral-src
Webpage: https://mistral.ai/news/announcing-mistral-7b/

Key moments:

1) grouped-query attention (GQA) for faster inference
   
2) sliding window attention (SWA) to effectively handle sequences of arbitrary length with a
reduced inference cost.

## Architecture
Mistral - transformer.

![image](https://github.com/BeksultanSagyndyk/BeksultanSagyndyk.github.io/assets/46630209/029c6e88-4374-4ef5-819e-9b67b8775b63)

#### Sliding Window Attention

Number of operations in vanilla attention is quadratic in the sequence length.

In SWA: each token can attend to at most W tokens from the previous layer (here, W = 3).

BUt tokens outside the sliding window still influence next word prediction

![image](https://github.com/BeksultanSagyndyk/BeksultanSagyndyk.github.io/assets/46630209/9d329656-dd96-4321-9948-172ce66c984f)

At each attention layer, information can move
forward by W tokens. Hence, after k attention layers, information can move forward by up to k Ã— W tokens.(figure 1)

#### Rolling Buffer Cache.

A fixed attention span means --> that we can limit our cache size.
1) The cache has a fixed size of W (= 3 in the picture example)
   
2) the keys and values for the timestep i are stored
in position i mod W of the cache.

3) when the position i > W, past values
in the cache are overwritten, and the size of the cache stops increasing.

![image](https://github.com/BeksultanSagyndyk/BeksultanSagyndyk.github.io/assets/46630209/91bf15a4-e8d8-464f-8ed5-611c6111f38f)
