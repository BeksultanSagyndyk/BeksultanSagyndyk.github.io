---
layout: post
title: "Paper Review 7: FlashAttention - Fast and Memory-Efficient Exact Attention with IO-Awareness"
subtitle: "IO-aware exact attention algorithm that uses tiling to reduce the number of memory reads/writes"
gh-repo: BeksultanSagyndyk/BeksultanSagyndyk.github.io
gh-badge: [star, follow]
tags: [efficiency, long input transformers]
comments: true
author: Beksultan Sagyndyk
---
<img width="627" alt="Screenshot 2024-02-06 at 14 43 59" src="https://github.com/BeksultanSagyndyk/BeksultanSagyndyk.github.io/assets/46630209/6ca75c46-0ab3-4910-b780-6bab0716a939">

